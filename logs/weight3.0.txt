ssh://nirvana@0df579c1e9b76a66.natapp.cc:2051/home/nirvana/hfai_envs/ssl_0/bin/python -u /home/nirvana/workspace/PycharmProjects/Semi-supervised-learning/train.py --c config/mlp_ssl_tiny/debug.yaml
Is local debug, reset attributes.
/home/nirvana/workspace/PycharmProjects/Semi-supervised-learning/train.py:54: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
[2023-04-28 00:45:23,912 INFO] Use GPU: 0 for training
Files already downloaded and verified
lb count: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
ulb count: [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Files already downloaded and verified
[2023-04-28 00:45:25,184 INFO] unlabeled data number: 50000, labeled data number 40
[2023-04-28 00:45:26,206 INFO] Create train and test data loaders
[2023-04-28 00:45:26,207 INFO] [!] data loader keys: dict_keys(['train_lb', 'train_ulb', 'eval'])
[2023-04-28 00:45:26,274 INFO] Create optimizer and scheduler
[2023-04-28 00:45:26,275 INFO] Number of Trainable Params: 1469771
[2023-04-28 00:45:26,296 INFO] Arguments: Namespace(T=0.5, algorithm='mlp_fixmatch', amp=False, backbone_temperature_scaling=1.0, batch_size=64, c='config/mlp_ssl_tiny/debug.yaml', calc_weight_method='mlp', class_mismatch_ratio=0, clip=0.0, clip_grad=0, crop_ratio=0.875, data_dir='./data', datadiet_adjust_lr_decay=False, datadiet_exp_version=0, datadiet_grad_params='backbone', datadiet_influence_calculate_num=1, datadiet_influence_group_size=448, datadiet_interval=1073741824, datadiet_keep_num=1073741824, datadiet_method=None, datadiet_val_grad_method='mixup', datadiet_warmup_epoch=40, dataset='cifar10', disable_shm=False, dist_backend='nccl', dist_url='tcp://127.0.0.1:16974', distributed=True, ema_m=0.999, epoch=1000, eval_batch_size=256, gpu=0, hard_label=True, imb_algorithm=None, img_size=32, l2_weight=3.0, layer_decay=1.0, lb_dest_len=40, lb_imb_ratio=1, load_path='None', lr=0.03, max_length=512, max_length_seconds=4.0, momentum=0.9, multiprocessing_distributed=True, net='mlp_wrn_28_2', net_from_name=False, num_classes=10, num_eval_iter=1000, num_labels=40, num_log_iter=10, num_train_iter=300000, num_warmup_iter=0, num_workers=0, optim='SGD', overwrite=True, p_cutoff=0.95, pretrain_path='', rank=0, resume=False, sample_rate=16000, save_dir='./saved_models/debug', save_interval=1000000000000, save_name='mlp_fixmatch_cifar10_40_4gpu', seed=0, train_sampler='RandomSampler', ulb_dest_len=50000, ulb_imb_ratio=1, ulb_loss_ratio=1.0, ulb_num_labels=None, uratio=7, use_amp=False, use_cat=True, use_pretrain=False, use_tensorboard=True, vcc_datapoint_bank_size=100, vcc_dec_model='early_fusion', vcc_dec_norm='none', vcc_decoder_dims=[256, 128], vcc_detach_input=False, vcc_disable_entropy=False, vcc_disable_temporal=False, vcc_disable_variance=False, vcc_disable_view=False, vcc_enc_norm='none', vcc_encoder_dims=[128, 256], vcc_lab_loss_weight=0.0, vcc_mc_dropsize=5, vcc_mc_keep_p=0.5, vcc_mc_sampling_times=20, vcc_mc_upd_ratio=1.0, vcc_only_supervised=False, vcc_p_cutoff=0.95, vcc_recon_loss='cross_entropy', vcc_reinit_threshold=False, vcc_selection_warmup=1073741824, vcc_training_warmup=1073741824, vcc_uncertainty_method='mcdropout', vcc_unlab_kl_loss_weight=0.0, vcc_unlab_recon_loss_weight=0.0, vcc_variance_warmup=0, vcc_z_dim=0, visualize_eval_results_path=None, visualize_load_path=None, weight_decay=0.0005, world_size=1)
[2023-04-28 00:45:26,296 INFO] Resume load path None does not exist
[2023-04-28 00:45:26,296 INFO] Model training
[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2023-04-28 00:45:28,861 INFO] model saved: ./saved_models/debug/mlp_fixmatch_cifar10_40_4gpu/model_best.pth
[2023-04-28 00:45:34,728 INFO] 10 iteration, USE_EMA: True, {'train/sup_loss': 1.644829273223877, 'train/unsup_loss': 0.5831056833267212, 'train/select_loss': 1.4938404560089111, 'train/total_loss': 3.7217752933502197, 'train/mask_ratio': 0.5020532608032227, 'lr': 0.029999999968514934, 'train/prefecth_time': 0.4327725830078125, 'train/run_time': 0.2190167694091797}
[2023-04-28 00:45:41,209 INFO] 20 iteration, USE_EMA: True, {'train/sup_loss': 0.6712551712989807, 'train/unsup_loss': 1.1326717138290405, 'train/select_loss': 1.344335675239563, 'train/total_loss': 3.1482625007629395, 'train/mask_ratio': 0.551888108253479, 'lr': 0.029999999874059734, 'train/prefecth_time': 0.4313822326660156, 'train/run_time': 0.21644210815429688}
[2023-04-28 00:45:47,691 INFO] 30 iteration, USE_EMA: True, {'train/sup_loss': 0.30810222029685974, 'train/unsup_loss': 1.1477549076080322, 'train/select_loss': 1.2276761531829834, 'train/total_loss': 2.683533191680908, 'train/mask_ratio': 0.590774655342102, 'lr': 0.029999999716634404, 'train/prefecth_time': 0.4311635437011719, 'train/run_time': 0.21637715148925782}
[2023-04-28 00:45:54,246 INFO] 40 iteration, USE_EMA: True, {'train/sup_loss': 0.06758274883031845, 'train/unsup_loss': 1.232596755027771, 'train/select_loss': 1.0635204315185547, 'train/total_loss': 2.3636999130249023, 'train/mask_ratio': 0.6454932689666748, 'lr': 0.02999999949623894, 'train/prefecth_time': 0.4351624755859375, 'train/run_time': 0.2186623992919922}
[2023-04-28 00:46:00,751 INFO] 50 iteration, USE_EMA: True, {'train/sup_loss': 0.14385853707790375, 'train/unsup_loss': 1.2430754899978638, 'train/select_loss': 0.9226954579353333, 'train/total_loss': 2.309629440307617, 'train/mask_ratio': 0.6924349069595337, 'lr': 0.029999999212873347, 'train/prefecth_time': 0.43270474243164064, 'train/run_time': 0.21647225952148438}
[2023-04-28 00:46:07,256 INFO] 60 iteration, USE_EMA: True, {'train/sup_loss': 0.08726406842470169, 'train/unsup_loss': 1.2978241443634033, 'train/select_loss': 0.7729765176773071, 'train/total_loss': 2.158064842224121, 'train/mask_ratio': 0.7423412203788757, 'lr': 0.029999998866537626, 'train/prefecth_time': 0.4316649169921875, 'train/run_time': 0.21653750610351563}
[2023-04-28 00:46:13,759 INFO] 70 iteration, USE_EMA: True, {'train/sup_loss': 0.047761429101228714, 'train/unsup_loss': 1.1641550064086914, 'train/select_loss': 0.6654966473579407, 'train/total_loss': 1.877413034439087, 'train/mask_ratio': 0.7781677842140198, 'lr': 0.029999998457231773, 'train/prefecth_time': 0.43092236328125, 'train/run_time': 0.21840080261230468}
[2023-04-28 00:46:20,250 INFO] 80 iteration, USE_EMA: True, {'train/sup_loss': 0.02634887956082821, 'train/unsup_loss': 1.341712474822998, 'train/select_loss': 0.5420269966125488, 'train/total_loss': 1.910088300704956, 'train/mask_ratio': 0.8193243741989136, 'lr': 0.02999999798495579, 'train/prefecth_time': 0.43133074951171874, 'train/run_time': 0.2170833282470703}
[2023-04-28 00:46:26,756 INFO] 90 iteration, USE_EMA: True, {'train/sup_loss': 0.032360345125198364, 'train/unsup_loss': 1.1914947032928467, 'train/select_loss': 0.4879012107849121, 'train/total_loss': 1.7117562294006348, 'train/mask_ratio': 0.8373662829399109, 'lr': 0.02999999744970968, 'train/prefecth_time': 0.43441387939453124, 'train/run_time': 0.2181610565185547}
[2023-04-28 00:46:33,266 INFO] 100 iteration, USE_EMA: True, {'train/sup_loss': 0.022938115522265434, 'train/unsup_loss': 1.1564010381698608, 'train/select_loss': 0.43382972478866577, 'train/total_loss': 1.6131689548492432, 'train/mask_ratio': 0.855390191078186, 'lr': 0.02999999685149344, 'train/prefecth_time': 0.432732666015625, 'train/run_time': 0.2174599609375}
[2023-04-28 00:46:39,762 INFO] 110 iteration, USE_EMA: True, {'train/sup_loss': 0.045480210334062576, 'train/unsup_loss': 1.1849305629730225, 'train/select_loss': 0.33351004123687744, 'train/total_loss': 1.5639208555221558, 'train/mask_ratio': 0.8888300061225891, 'lr': 0.029999996190307077, 'train/prefecth_time': 0.4292713623046875, 'train/run_time': 0.21702899169921874}
[2023-04-28 00:46:46,269 INFO] 120 iteration, USE_EMA: True, {'train/sup_loss': 0.017944395542144775, 'train/unsup_loss': 1.0867414474487305, 'train/select_loss': 0.32405006885528564, 'train/total_loss': 1.4287358522415161, 'train/mask_ratio': 0.8919833302497864, 'lr': 0.029999995466150592, 'train/prefecth_time': 0.43062893676757813, 'train/run_time': 0.21826406860351563}
[2023-04-28 00:46:52,767 INFO] 130 iteration, USE_EMA: True, {'train/sup_loss': 0.019791772589087486, 'train/unsup_loss': 1.1440410614013672, 'train/select_loss': 0.28134268522262573, 'train/total_loss': 1.4451754093170166, 'train/mask_ratio': 0.9062191247940063, 'lr': 0.02999999467902398, 'train/prefecth_time': 0.43444473266601563, 'train/run_time': 0.21706300354003907}
[2023-04-28 00:46:59,253 INFO] 140 iteration, USE_EMA: True, {'train/sup_loss': 0.03812239319086075, 'train/unsup_loss': 1.304397702217102, 'train/select_loss': 0.3322354555130005, 'train/total_loss': 1.674755573272705, 'train/mask_ratio': 0.8892548680305481, 'lr': 0.02999999382892725, 'train/prefecth_time': 0.4311263122558594, 'train/run_time': 0.2168956756591797}
[2023-04-28 00:47:05,758 INFO] 150 iteration, USE_EMA: True, {'train/sup_loss': 0.02487226016819477, 'train/unsup_loss': 1.5132390260696411, 'train/select_loss': 0.32967203855514526, 'train/total_loss': 1.8677833080291748, 'train/mask_ratio': 0.8901093602180481, 'lr': 0.0299999929158604, 'train/prefecth_time': 0.431126708984375, 'train/run_time': 0.2181094970703125}
[2023-04-28 00:47:12,263 INFO] 160 iteration, USE_EMA: True, {'train/sup_loss': 0.019741330295801163, 'train/unsup_loss': 1.4614291191101074, 'train/select_loss': 0.28834274411201477, 'train/total_loss': 1.7695131301879883, 'train/mask_ratio': 0.9038858413696289, 'lr': 0.02999999193982343, 'train/prefecth_time': 0.4343538818359375, 'train/run_time': 0.21805606079101564}
[2023-04-28 00:47:18,769 INFO] 170 iteration, USE_EMA: True, {'train/sup_loss': 0.028255488723516464, 'train/unsup_loss': 1.268281102180481, 'train/select_loss': 0.26658910512924194, 'train/total_loss': 1.5631256103515625, 'train/mask_ratio': 0.9111371040344238, 'lr': 0.02999999090081635, 'train/prefecth_time': 0.43230712890625, 'train/run_time': 0.21847785949707033}
[2023-04-28 00:47:25,257 INFO] 180 iteration, USE_EMA: True, {'train/sup_loss': 0.017434505745768547, 'train/unsup_loss': 1.149214267730713, 'train/select_loss': 0.22098734974861145, 'train/total_loss': 1.3876360654830933, 'train/mask_ratio': 0.9263375997543335, 'lr': 0.029999989798839152, 'train/prefecth_time': 0.4321607971191406, 'train/run_time': 0.21679530334472658}
[2023-04-28 00:47:31,757 INFO] 190 iteration, USE_EMA: True, {'train/sup_loss': 0.014912351034581661, 'train/unsup_loss': 1.137352466583252, 'train/select_loss': 0.2009499967098236, 'train/total_loss': 1.3532148599624634, 'train/mask_ratio': 0.9330166578292847, 'lr': 0.029999988633891847, 'train/prefecth_time': 0.4337623596191406, 'train/run_time': 0.21935702514648436}
[2023-04-28 00:47:38,269 INFO] 200 iteration, USE_EMA: True, {'train/sup_loss': 0.01717330887913704, 'train/unsup_loss': 1.1952180862426758, 'train/select_loss': 0.19210326671600342, 'train/total_loss': 1.4044946432113647, 'train/mask_ratio': 0.9359655976295471, 'lr': 0.02999998740597443, 'train/prefecth_time': 0.43312127685546875, 'train/run_time': 0.21805821228027344}
[2023-04-28 00:47:44,762 INFO] 210 iteration, USE_EMA: True, {'train/sup_loss': 0.019755739718675613, 'train/unsup_loss': 1.1200917959213257, 'train/select_loss': 0.1907433271408081, 'train/total_loss': 1.330590844154358, 'train/mask_ratio': 0.936418890953064, 'lr': 0.029999986115086908, 'train/prefecth_time': 0.43055679321289064, 'train/run_time': 0.217031494140625}
[2023-04-28 00:47:51,279 INFO] 220 iteration, USE_EMA: True, {'train/sup_loss': 0.029790660366415977, 'train/unsup_loss': 1.1069198846817017, 'train/select_loss': 0.16593140363693237, 'train/total_loss': 1.3026418685913086, 'train/mask_ratio': 0.9446895718574524, 'lr': 0.02999998476122929, 'train/prefecth_time': 0.4333531494140625, 'train/run_time': 0.2185302734375}
[2023-04-28 00:47:57,780 INFO] 230 iteration, USE_EMA: True, {'train/sup_loss': 0.008284511044621468, 'train/unsup_loss': 1.258603572845459, 'train/select_loss': 0.19003786146640778, 'train/total_loss': 1.4569259881973267, 'train/mask_ratio': 0.9366541504859924, 'lr': 0.02999998334440156, 'train/prefecth_time': 0.4343518981933594, 'train/run_time': 0.21735328674316406}
[2023-04-28 00:48:04,281 INFO] 240 iteration, USE_EMA: True, {'train/sup_loss': 0.0159312654286623, 'train/unsup_loss': 1.0190623998641968, 'train/select_loss': 0.15498095750808716, 'train/total_loss': 1.1899745464324951, 'train/mask_ratio': 0.9483397006988525, 'lr': 0.029999981864603738, 'train/prefecth_time': 0.4330133972167969, 'train/run_time': 0.21722647094726563}
[2023-04-28 00:48:10,791 INFO] 250 iteration, USE_EMA: True, {'train/sup_loss': 0.011312919668853283, 'train/unsup_loss': 0.9695664644241333, 'train/select_loss': 0.139704167842865, 'train/total_loss': 1.1205835342407227, 'train/mask_ratio': 0.9534319639205933, 'lr': 0.029999980321835824, 'train/prefecth_time': 0.43150390625, 'train/run_time': 0.2172972869873047}
[2023-04-28 00:48:17,298 INFO] 260 iteration, USE_EMA: True, {'train/sup_loss': 0.010431868024170399, 'train/unsup_loss': 1.0073455572128296, 'train/select_loss': 0.1224522516131401, 'train/total_loss': 1.1402297019958496, 'train/mask_ratio': 0.959182620048523, 'lr': 0.029999978716097817, 'train/prefecth_time': 0.4307237548828125, 'train/run_time': 0.21728857421875}
[2023-04-28 00:48:23,794 INFO] 270 iteration, USE_EMA: True, {'train/sup_loss': 0.2273397445678711, 'train/unsup_loss': 0.864753782749176, 'train/select_loss': 0.1535586416721344, 'train/total_loss': 1.2456520795822144, 'train/mask_ratio': 0.9488139152526855, 'lr': 0.029999977047389725, 'train/prefecth_time': 0.43132989501953123, 'train/run_time': 0.217468994140625}
