ssh://nirvana@0df579c1e9b76a66.natapp.cc:2051/home/nirvana/hfai_envs/ssl_0/bin/python -u /home/nirvana/workspace/PycharmProjects/Semi-supervised-learning/train.py --c config/mlp_ssl_tiny/debug.yaml
Is local debug, reset attributes.
/home/nirvana/workspace/PycharmProjects/Semi-supervised-learning/train.py:54: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
[2023-04-28 00:57:55,692 INFO] Use GPU: 0 for training
Files already downloaded and verified
lb count: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
ulb count: [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Files already downloaded and verified
[2023-04-28 00:57:56,963 INFO] unlabeled data number: 50000, labeled data number 40
[2023-04-28 00:57:57,997 INFO] Create train and test data loaders
[2023-04-28 00:57:57,998 INFO] [!] data loader keys: dict_keys(['train_lb', 'train_ulb', 'eval'])
[2023-04-28 00:57:58,063 INFO] Create optimizer and scheduler
[2023-04-28 00:57:58,064 INFO] Number of Trainable Params: 1469771
[2023-04-28 00:57:58,085 INFO] Arguments: Namespace(T=0.5, algorithm='mlp_fixmatch', amp=False, backbone_temperature_scaling=1.0, batch_size=64, c='config/mlp_ssl_tiny/debug.yaml', calc_weight_method='softmax', class_mismatch_ratio=0, clip=0.0, clip_grad=0, crop_ratio=0.875, data_dir='./data', datadiet_adjust_lr_decay=False, datadiet_exp_version=0, datadiet_grad_params='backbone', datadiet_influence_calculate_num=1, datadiet_influence_group_size=448, datadiet_interval=1073741824, datadiet_keep_num=1073741824, datadiet_method=None, datadiet_val_grad_method='mixup', datadiet_warmup_epoch=40, dataset='cifar10', disable_shm=False, dist_backend='nccl', dist_url='tcp://127.0.0.1:15490', distributed=True, ema_m=0.999, epoch=1000, eval_batch_size=256, gpu=0, hard_label=True, imb_algorithm=None, img_size=32, l2_weight=0.0, layer_decay=1.0, lb_dest_len=40, lb_imb_ratio=1, load_path='None', lr=0.03, max_length=512, max_length_seconds=4.0, momentum=0.9, multiprocessing_distributed=True, net='mlp_wrn_28_2', net_from_name=False, num_classes=10, num_eval_iter=1000, num_labels=40, num_log_iter=10, num_train_iter=300000, num_warmup_iter=0, num_workers=0, optim='SGD', overwrite=True, p_cutoff=0.95, pretrain_path='', rank=0, resume=False, sample_rate=16000, save_dir='./saved_models/debug', save_interval=1000000000000, save_name='mlp_fixmatch_cifar10_40_4gpu', seed=0, train_sampler='RandomSampler', ulb_dest_len=50000, ulb_imb_ratio=1, ulb_loss_ratio=1.0, ulb_num_labels=None, uratio=7, use_amp=False, use_cat=True, use_pretrain=False, use_tensorboard=True, vcc_datapoint_bank_size=100, vcc_dec_model='early_fusion', vcc_dec_norm='none', vcc_decoder_dims=[256, 128], vcc_detach_input=False, vcc_disable_entropy=False, vcc_disable_temporal=False, vcc_disable_variance=False, vcc_disable_view=False, vcc_enc_norm='none', vcc_encoder_dims=[128, 256], vcc_lab_loss_weight=0.0, vcc_mc_dropsize=5, vcc_mc_keep_p=0.5, vcc_mc_sampling_times=20, vcc_mc_upd_ratio=1.0, vcc_only_supervised=False, vcc_p_cutoff=0.95, vcc_recon_loss='cross_entropy', vcc_reinit_threshold=False, vcc_selection_warmup=1073741824, vcc_training_warmup=1073741824, vcc_uncertainty_method='mcdropout', vcc_unlab_kl_loss_weight=0.0, vcc_unlab_recon_loss_weight=0.0, vcc_variance_warmup=0, vcc_z_dim=0, visualize_eval_results_path=None, visualize_load_path=None, weight_decay=0.0005, world_size=1)
[2023-04-28 00:57:58,085 INFO] Resume load path None does not exist
[2023-04-28 00:57:58,085 INFO] Model training
[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2023-04-28 00:58:00,654 INFO] model saved: ./saved_models/debug/mlp_fixmatch_cifar10_40_4gpu/model_best.pth
[2023-04-28 00:58:06,503 INFO] 10 iteration, USE_EMA: True, {'train/sup_loss': 1.613664984703064, 'train/unsup_loss': 0.8148981928825378, 'train/select_loss': -0.0, 'train/total_loss': 2.428563117980957, 'train/mask_ratio': 1.0, 'lr': 0.029999999968514934, 'train/prefecth_time': 0.4302198791503906, 'train/run_time': 0.2159718017578125}
[2023-04-28 00:58:12,969 INFO] 20 iteration, USE_EMA: True, {'train/sup_loss': 0.9454122185707092, 'train/unsup_loss': 1.7891230583190918, 'train/select_loss': -0.0, 'train/total_loss': 2.7345352172851562, 'train/mask_ratio': 1.0, 'lr': 0.029999999874059734, 'train/prefecth_time': 0.4305952758789062, 'train/run_time': 0.2165641632080078}
[2023-04-28 00:58:19,437 INFO] 30 iteration, USE_EMA: True, {'train/sup_loss': 0.40355485677719116, 'train/unsup_loss': 1.8618767261505127, 'train/select_loss': 0.0, 'train/total_loss': 2.2654316425323486, 'train/mask_ratio': 0.9999998807907104, 'lr': 0.029999999716634404, 'train/prefecth_time': 0.43065966796875, 'train/run_time': 0.2172151336669922}
[2023-04-28 00:58:25,982 INFO] 40 iteration, USE_EMA: True, {'train/sup_loss': 0.13330282270908356, 'train/unsup_loss': 1.9228695631027222, 'train/select_loss': -0.0, 'train/total_loss': 2.0561723709106445, 'train/mask_ratio': 1.0, 'lr': 0.02999999949623894, 'train/prefecth_time': 0.4348288879394531, 'train/run_time': 0.21759756469726563}
[2023-04-28 00:58:32,479 INFO] 50 iteration, USE_EMA: True, {'train/sup_loss': 0.10724817216396332, 'train/unsup_loss': 1.7185131311416626, 'train/select_loss': 0.0, 'train/total_loss': 1.825761318206787, 'train/mask_ratio': 1.0, 'lr': 0.029999999212873347, 'train/prefecth_time': 0.43152783203125, 'train/run_time': 0.2168956756591797}
[2023-04-28 00:58:38,986 INFO] 60 iteration, USE_EMA: True, {'train/sup_loss': 0.04321250319480896, 'train/unsup_loss': 1.6187759637832642, 'train/select_loss': 0.0, 'train/total_loss': 1.6619884967803955, 'train/mask_ratio': 1.0, 'lr': 0.029999998866537626, 'train/prefecth_time': 0.43355484008789064, 'train/run_time': 0.21874383544921874}
[2023-04-28 00:58:45,498 INFO] 70 iteration, USE_EMA: True, {'train/sup_loss': 0.05402050539851189, 'train/unsup_loss': 1.4749314785003662, 'train/select_loss': -0.0, 'train/total_loss': 1.5289520025253296, 'train/mask_ratio': 1.0, 'lr': 0.029999998457231773, 'train/prefecth_time': 0.4321597900390625, 'train/run_time': 0.21817106628417968}
[2023-04-28 00:58:51,998 INFO] 80 iteration, USE_EMA: True, {'train/sup_loss': 0.12946148216724396, 'train/unsup_loss': 1.6241304874420166, 'train/select_loss': 0.0, 'train/total_loss': 1.7535920143127441, 'train/mask_ratio': 1.0, 'lr': 0.02999999798495579, 'train/prefecth_time': 0.4308593139648437, 'train/run_time': 0.21683010864257812}
[2023-04-28 00:58:58,507 INFO] 90 iteration, USE_EMA: True, {'train/sup_loss': 0.03036041185259819, 'train/unsup_loss': 1.561995029449463, 'train/select_loss': -0.0, 'train/total_loss': 1.592355489730835, 'train/mask_ratio': 1.0, 'lr': 0.02999999744970968, 'train/prefecth_time': 0.43399423217773436, 'train/run_time': 0.21706002807617186}
[2023-04-28 00:59:05,018 INFO] 100 iteration, USE_EMA: True, {'train/sup_loss': 0.05903230980038643, 'train/unsup_loss': 1.4913324117660522, 'train/select_loss': -0.0, 'train/total_loss': 1.5503647327423096, 'train/mask_ratio': 1.0, 'lr': 0.02999999685149344, 'train/prefecth_time': 0.43272210693359375, 'train/run_time': 0.21777276611328125}
[2023-04-28 00:59:11,524 INFO] 110 iteration, USE_EMA: True, {'train/sup_loss': 0.022511402145028114, 'train/unsup_loss': 1.5568349361419678, 'train/select_loss': 0.0, 'train/total_loss': 1.5793462991714478, 'train/mask_ratio': 1.0, 'lr': 0.029999996190307077, 'train/prefecth_time': 0.429959228515625, 'train/run_time': 0.21930085754394532}
[2023-04-28 00:59:18,034 INFO] 120 iteration, USE_EMA: True, {'train/sup_loss': 0.04351723566651344, 'train/unsup_loss': 1.5178804397583008, 'train/select_loss': 0.0, 'train/total_loss': 1.561397671699524, 'train/mask_ratio': 1.0, 'lr': 0.029999995466150592, 'train/prefecth_time': 0.43212066650390624, 'train/run_time': 0.21838088989257812}
[2023-04-28 00:59:24,537 INFO] 130 iteration, USE_EMA: True, {'train/sup_loss': 0.019246088340878487, 'train/unsup_loss': 1.3579392433166504, 'train/select_loss': -0.0, 'train/total_loss': 1.377185344696045, 'train/mask_ratio': 1.0, 'lr': 0.02999999467902398, 'train/prefecth_time': 0.4346379089355469, 'train/run_time': 0.2176607666015625}
[2023-04-28 00:59:31,026 INFO] 140 iteration, USE_EMA: True, {'train/sup_loss': 0.02250836044549942, 'train/unsup_loss': 1.2205718755722046, 'train/select_loss': 0.0, 'train/total_loss': 1.2430802583694458, 'train/mask_ratio': 1.0, 'lr': 0.02999999382892725, 'train/prefecth_time': 0.43163705444335937, 'train/run_time': 0.21699766540527343}
[2023-04-28 00:59:37,533 INFO] 150 iteration, USE_EMA: True, {'train/sup_loss': 0.017304550856351852, 'train/unsup_loss': 1.2547385692596436, 'train/select_loss': 0.0, 'train/total_loss': 1.2720431089401245, 'train/mask_ratio': 0.9999998807907104, 'lr': 0.0299999929158604, 'train/prefecth_time': 0.432058837890625, 'train/run_time': 0.21675686645507813}
[2023-04-28 00:59:44,050 INFO] 160 iteration, USE_EMA: True, {'train/sup_loss': 0.02575242705643177, 'train/unsup_loss': 1.178629994392395, 'train/select_loss': 0.0, 'train/total_loss': 1.2043824195861816, 'train/mask_ratio': 1.0, 'lr': 0.02999999193982343, 'train/prefecth_time': 0.4356394348144531, 'train/run_time': 0.2195116729736328}
[2023-04-28 00:59:50,565 INFO] 170 iteration, USE_EMA: True, {'train/sup_loss': 0.01716175116598606, 'train/unsup_loss': 1.1522517204284668, 'train/select_loss': 0.0, 'train/total_loss': 1.169413447380066, 'train/mask_ratio': 1.0, 'lr': 0.02999999090081635, 'train/prefecth_time': 0.4343158264160156, 'train/run_time': 0.21861753845214843}
[2023-04-28 00:59:57,070 INFO] 180 iteration, USE_EMA: True, {'train/sup_loss': 0.01723324880003929, 'train/unsup_loss': 1.182468295097351, 'train/select_loss': 0.0, 'train/total_loss': 1.1997015476226807, 'train/mask_ratio': 1.0, 'lr': 0.029999989798839152, 'train/prefecth_time': 0.4332410278320312, 'train/run_time': 0.21749942016601562}
[2023-04-28 01:00:03,574 INFO] 190 iteration, USE_EMA: True, {'train/sup_loss': 0.025963451713323593, 'train/unsup_loss': 0.9337397813796997, 'train/select_loss': -0.0, 'train/total_loss': 0.9597032070159912, 'train/mask_ratio': 1.0000001192092896, 'lr': 0.029999988633891847, 'train/prefecth_time': 0.43198480224609376, 'train/run_time': 0.2189001007080078}
[2023-04-28 01:00:10,092 INFO] 200 iteration, USE_EMA: True, {'train/sup_loss': 0.02747180685400963, 'train/unsup_loss': 1.0600495338439941, 'train/select_loss': -0.0, 'train/total_loss': 1.0875213146209717, 'train/mask_ratio': 1.0000001192092896, 'lr': 0.02999998740597443, 'train/prefecth_time': 0.43295956420898435, 'train/run_time': 0.2171138916015625}
[2023-04-28 01:00:16,601 INFO] 210 iteration, USE_EMA: True, {'train/sup_loss': 0.03780997171998024, 'train/unsup_loss': 1.040067195892334, 'train/select_loss': 0.0, 'train/total_loss': 1.077877163887024, 'train/mask_ratio': 1.0, 'lr': 0.029999986115086908, 'train/prefecth_time': 0.43164715576171875, 'train/run_time': 0.21689840698242188}
[2023-04-28 01:00:23,125 INFO] 220 iteration, USE_EMA: True, {'train/sup_loss': 0.040191102772951126, 'train/unsup_loss': 1.157025933265686, 'train/select_loss': 0.0, 'train/total_loss': 1.1972169876098633, 'train/mask_ratio': 1.0, 'lr': 0.02999998476122929, 'train/prefecth_time': 0.4343187255859375, 'train/run_time': 0.21964215087890626}
[2023-04-28 01:00:29,631 INFO] 230 iteration, USE_EMA: True, {'train/sup_loss': 0.014683805406093597, 'train/unsup_loss': 1.2141027450561523, 'train/select_loss': 0.0, 'train/total_loss': 1.228786587715149, 'train/mask_ratio': 1.0, 'lr': 0.02999998334440156, 'train/prefecth_time': 0.43375811767578126, 'train/run_time': 0.21823606872558593}
[2023-04-28 01:00:36,136 INFO] 240 iteration, USE_EMA: True, {'train/sup_loss': 0.014563020318746567, 'train/unsup_loss': 1.102469801902771, 'train/select_loss': -0.0, 'train/total_loss': 1.117032766342163, 'train/mask_ratio': 1.0, 'lr': 0.029999981864603738, 'train/prefecth_time': 0.4322544250488281, 'train/run_time': 0.21820716857910155}
[2023-04-28 01:00:42,643 INFO] 250 iteration, USE_EMA: True, {'train/sup_loss': 0.008057755418121815, 'train/unsup_loss': 1.216165542602539, 'train/select_loss': 0.0, 'train/total_loss': 1.224223256111145, 'train/mask_ratio': 1.0, 'lr': 0.029999980321835824, 'train/prefecth_time': 0.43103909301757815, 'train/run_time': 0.21927587890625}
[2023-04-28 01:00:49,154 INFO] 260 iteration, USE_EMA: True, {'train/sup_loss': 0.009808691218495369, 'train/unsup_loss': 1.1266846656799316, 'train/select_loss': 0.0, 'train/total_loss': 1.1364933252334595, 'train/mask_ratio': 0.9999998807907104, 'lr': 0.029999978716097817, 'train/prefecth_time': 0.4318799743652344, 'train/run_time': 0.21855194091796876}
[2023-04-28 01:00:55,648 INFO] 270 iteration, USE_EMA: True, {'train/sup_loss': 0.013334685005247593, 'train/unsup_loss': 1.0006883144378662, 'train/select_loss': -0.0, 'train/total_loss': 1.014022946357727, 'train/mask_ratio': 1.0, 'lr': 0.029999977047389725, 'train/prefecth_time': 0.43051107788085935, 'train/run_time': 0.2182879638671875}
