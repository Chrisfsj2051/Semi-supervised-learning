ssh://nirvana@0df579c1e9b76a66.natapp.cc:2051/home/nirvana/hfai_envs/ssl_0/bin/python -u /home/nirvana/workspace/PycharmProjects/Semi-supervised-learning/train.py --c config/mlp_ssl_tiny/debug.yaml
Is local debug, reset attributes.
/home/nirvana/workspace/PycharmProjects/Semi-supervised-learning/train.py:54: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
[2023-04-28 00:42:35,875 INFO] Use GPU: 0 for training
Files already downloaded and verified
lb count: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
ulb count: [5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]
Files already downloaded and verified
[2023-04-28 00:42:37,147 INFO] unlabeled data number: 50000, labeled data number 40
[2023-04-28 00:42:38,172 INFO] Create train and test data loaders
[2023-04-28 00:42:38,172 INFO] [!] data loader keys: dict_keys(['train_lb', 'train_ulb', 'eval'])
[2023-04-28 00:42:38,243 INFO] Create optimizer and scheduler
[2023-04-28 00:42:38,244 INFO] Number of Trainable Params: 1469771
[2023-04-28 00:42:38,265 INFO] Arguments: Namespace(T=0.5, algorithm='mlp_fixmatch', amp=False, backbone_temperature_scaling=1.0, batch_size=64, c='config/mlp_ssl_tiny/debug.yaml', calc_weight_method='mlp', class_mismatch_ratio=0, clip=0.0, clip_grad=0, crop_ratio=0.875, data_dir='./data', datadiet_adjust_lr_decay=False, datadiet_exp_version=0, datadiet_grad_params='backbone', datadiet_influence_calculate_num=1, datadiet_influence_group_size=448, datadiet_interval=1073741824, datadiet_keep_num=1073741824, datadiet_method=None, datadiet_val_grad_method='mixup', datadiet_warmup_epoch=40, dataset='cifar10', disable_shm=False, dist_backend='nccl', dist_url='tcp://127.0.0.1:16835', distributed=True, ema_m=0.999, epoch=1000, eval_batch_size=256, gpu=0, hard_label=True, imb_algorithm=None, img_size=32, l2_weight=1.0, layer_decay=1.0, lb_dest_len=40, lb_imb_ratio=1, load_path='None', lr=0.03, max_length=512, max_length_seconds=4.0, momentum=0.9, multiprocessing_distributed=True, net='mlp_wrn_28_2', net_from_name=False, num_classes=10, num_eval_iter=1000, num_labels=40, num_log_iter=10, num_train_iter=300000, num_warmup_iter=0, num_workers=0, optim='SGD', overwrite=True, p_cutoff=0.95, pretrain_path='', rank=0, resume=False, sample_rate=16000, save_dir='./saved_models/debug', save_interval=1000000000000, save_name='mlp_fixmatch_cifar10_40_4gpu', seed=0, train_sampler='RandomSampler', ulb_dest_len=50000, ulb_imb_ratio=1, ulb_loss_ratio=1.0, ulb_num_labels=None, uratio=7, use_amp=False, use_cat=True, use_pretrain=False, use_tensorboard=True, vcc_datapoint_bank_size=100, vcc_dec_model='early_fusion', vcc_dec_norm='none', vcc_decoder_dims=[256, 128], vcc_detach_input=False, vcc_disable_entropy=False, vcc_disable_temporal=False, vcc_disable_variance=False, vcc_disable_view=False, vcc_enc_norm='none', vcc_encoder_dims=[128, 256], vcc_lab_loss_weight=0.0, vcc_mc_dropsize=5, vcc_mc_keep_p=0.5, vcc_mc_sampling_times=20, vcc_mc_upd_ratio=1.0, vcc_only_supervised=False, vcc_p_cutoff=0.95, vcc_recon_loss='cross_entropy', vcc_reinit_threshold=False, vcc_selection_warmup=1073741824, vcc_training_warmup=1073741824, vcc_uncertainty_method='mcdropout', vcc_unlab_kl_loss_weight=0.0, vcc_unlab_recon_loss_weight=0.0, vcc_variance_warmup=0, vcc_z_dim=0, visualize_eval_results_path=None, visualize_load_path=None, weight_decay=0.0005, world_size=1)
[2023-04-28 00:42:38,265 INFO] Resume load path None does not exist
[2023-04-28 00:42:38,265 INFO] Model training
[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2023-04-28 00:42:40,836 INFO] model saved: ./saved_models/debug/mlp_fixmatch_cifar10_40_4gpu/model_best.pth
[2023-04-28 00:42:46,701 INFO] 10 iteration, USE_EMA: True, {'train/sup_loss': 1.3650156259536743, 'train/unsup_loss': 0.4916519224643707, 'train/select_loss': 0.5498982667922974, 'train/total_loss': 2.4065656661987305, 'train/mask_ratio': 0.450101763010025, 'lr': 0.029999999968514934, 'train/prefecth_time': 0.4342024841308594, 'train/run_time': 0.216198974609375}
[2023-04-28 00:42:53,185 INFO] 20 iteration, USE_EMA: True, {'train/sup_loss': 0.49934399127960205, 'train/unsup_loss': 0.8072715401649475, 'train/select_loss': 0.5726019740104675, 'train/total_loss': 1.8792176246643066, 'train/mask_ratio': 0.42739805579185486, 'lr': 0.029999999874059734, 'train/prefecth_time': 0.4320180358886719, 'train/run_time': 0.21692112731933594}
[2023-04-28 00:42:59,658 INFO] 30 iteration, USE_EMA: True, {'train/sup_loss': 0.5404971837997437, 'train/unsup_loss': 0.8413746953010559, 'train/select_loss': 0.603981614112854, 'train/total_loss': 1.9858535528182983, 'train/mask_ratio': 0.39601844549179077, 'lr': 0.029999999716634404, 'train/prefecth_time': 0.43269277954101565, 'train/run_time': 0.21643696594238282}
[2023-04-28 00:43:06,210 INFO] 40 iteration, USE_EMA: True, {'train/sup_loss': 0.09171456843614578, 'train/unsup_loss': 0.7084397077560425, 'train/select_loss': 0.6556493639945984, 'train/total_loss': 1.455803632736206, 'train/mask_ratio': 0.3443506956100464, 'lr': 0.02999999949623894, 'train/prefecth_time': 0.435249755859375, 'train/run_time': 0.2170417022705078}
[2023-04-28 00:43:12,707 INFO] 50 iteration, USE_EMA: True, {'train/sup_loss': 0.03108704276382923, 'train/unsup_loss': 0.5871267914772034, 'train/select_loss': 0.691760241985321, 'train/total_loss': 1.3099740743637085, 'train/mask_ratio': 0.3082398474216461, 'lr': 0.029999999212873347, 'train/prefecth_time': 0.4319974670410156, 'train/run_time': 0.21626170349121093}
[2023-04-28 00:43:19,215 INFO] 60 iteration, USE_EMA: True, {'train/sup_loss': 0.01798148825764656, 'train/unsup_loss': 0.5324693918228149, 'train/select_loss': 0.7308302521705627, 'train/total_loss': 1.2812811136245728, 'train/mask_ratio': 0.2691698670387268, 'lr': 0.029999998866537626, 'train/prefecth_time': 0.43195941162109375, 'train/run_time': 0.2169397735595703}
[2023-04-28 00:43:25,726 INFO] 70 iteration, USE_EMA: True, {'train/sup_loss': 0.016013670712709427, 'train/unsup_loss': 0.4476795196533203, 'train/select_loss': 0.7571857571601868, 'train/total_loss': 1.2208789587020874, 'train/mask_ratio': 0.24281424283981323, 'lr': 0.029999998457231773, 'train/prefecth_time': 0.4327741394042969, 'train/run_time': 0.21659519958496093}
[2023-04-28 00:43:32,234 INFO] 80 iteration, USE_EMA: True, {'train/sup_loss': 0.015054448507726192, 'train/unsup_loss': 0.3886070251464844, 'train/select_loss': 0.7847464084625244, 'train/total_loss': 1.1884078979492188, 'train/mask_ratio': 0.21525363624095917, 'lr': 0.02999999798495579, 'train/prefecth_time': 0.431553466796875, 'train/run_time': 0.21662007141113282}
[2023-04-28 00:43:38,756 INFO] 90 iteration, USE_EMA: True, {'train/sup_loss': 0.015891538932919502, 'train/unsup_loss': 0.33483394980430603, 'train/select_loss': 0.806938886642456, 'train/total_loss': 1.15766441822052, 'train/mask_ratio': 0.19306114315986633, 'lr': 0.02999999744970968, 'train/prefecth_time': 0.43491998291015627, 'train/run_time': 0.21766256713867188}
[2023-04-28 00:43:45,279 INFO] 100 iteration, USE_EMA: True, {'train/sup_loss': 0.006397089455276728, 'train/unsup_loss': 0.29681313037872314, 'train/select_loss': 0.819205641746521, 'train/total_loss': 1.1224159002304077, 'train/mask_ratio': 0.18079431354999542, 'lr': 0.02999999685149344, 'train/prefecth_time': 0.4334469909667969, 'train/run_time': 0.21851852416992187}
[2023-04-28 00:43:51,797 INFO] 110 iteration, USE_EMA: True, {'train/sup_loss': 0.008800588548183441, 'train/unsup_loss': 0.25264135003089905, 'train/select_loss': 0.8500078916549683, 'train/total_loss': 1.1114498376846313, 'train/mask_ratio': 0.14999213814735413, 'lr': 0.029999996190307077, 'train/prefecth_time': 0.431717529296875, 'train/run_time': 0.21741328430175783}
[2023-04-28 00:43:58,319 INFO] 120 iteration, USE_EMA: True, {'train/sup_loss': 0.005375994835048914, 'train/unsup_loss': 0.25555410981178284, 'train/select_loss': 0.8498221039772034, 'train/total_loss': 1.1107522249221802, 'train/mask_ratio': 0.1501779407262802, 'lr': 0.029999995466150592, 'train/prefecth_time': 0.43249267578125, 'train/run_time': 0.219845947265625}
[2023-04-28 00:44:04,837 INFO] 130 iteration, USE_EMA: True, {'train/sup_loss': 0.005747749004513025, 'train/unsup_loss': 0.20836932957172394, 'train/select_loss': 0.8760706186294556, 'train/total_loss': 1.090187668800354, 'train/mask_ratio': 0.1239294707775116, 'lr': 0.02999999467902398, 'train/prefecth_time': 0.4355366821289062, 'train/run_time': 0.21887234497070313}
[2023-04-28 00:44:11,342 INFO] 140 iteration, USE_EMA: True, {'train/sup_loss': 0.005192435346543789, 'train/unsup_loss': 0.19778405129909515, 'train/select_loss': 0.8802511692047119, 'train/total_loss': 1.0832276344299316, 'train/mask_ratio': 0.11974886059761047, 'lr': 0.02999999382892725, 'train/prefecth_time': 0.4324421081542969, 'train/run_time': 0.21902761840820312}
[2023-04-28 00:44:17,863 INFO] 150 iteration, USE_EMA: True, {'train/sup_loss': 0.004217797890305519, 'train/unsup_loss': 0.2005729079246521, 'train/select_loss': 0.8817734718322754, 'train/total_loss': 1.0865641832351685, 'train/mask_ratio': 0.11822661757469177, 'lr': 0.0299999929158604, 'train/prefecth_time': 0.4328021545410156, 'train/run_time': 0.2174051513671875}
[2023-04-28 00:44:24,386 INFO] 160 iteration, USE_EMA: True, {'train/sup_loss': 0.003572245128452778, 'train/unsup_loss': 0.16948866844177246, 'train/select_loss': 0.8911956548690796, 'train/total_loss': 1.0642565488815308, 'train/mask_ratio': 0.1088043823838234, 'lr': 0.02999999193982343, 'train/prefecth_time': 0.435462158203125, 'train/run_time': 0.2188236083984375}
[2023-04-28 00:44:30,913 INFO] 170 iteration, USE_EMA: True, {'train/sup_loss': 0.004701978527009487, 'train/unsup_loss': 0.16769592463970184, 'train/select_loss': 0.8971543908119202, 'train/total_loss': 1.0695523023605347, 'train/mask_ratio': 0.102845698595047, 'lr': 0.02999999090081635, 'train/prefecth_time': 0.4347252197265625, 'train/run_time': 0.22020614624023438}
[2023-04-28 00:44:37,424 INFO] 180 iteration, USE_EMA: True, {'train/sup_loss': 0.0031862754840403795, 'train/unsup_loss': 0.13771750032901764, 'train/select_loss': 0.9125387072563171, 'train/total_loss': 1.0534424781799316, 'train/mask_ratio': 0.08746132254600525, 'lr': 0.029999989798839152, 'train/prefecth_time': 0.4330906372070312, 'train/run_time': 0.21824934387207032}
